{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeanIn_NLP_Language_Modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JPwhm4fJFPTW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shruti3000/LeanIn_July2021_NLP_ShrutiBansal/blob/main/LeanIn_NLP_Language_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgv5zK3Z4z2v"
      },
      "source": [
        "# Importing all Important libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHApEF6M4uOt",
        "outputId": "adf4326a-b1ff-4955-cbc6-d9b0f0681524"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yntIKfYm3u_j"
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4FKSonc5G8b"
      },
      "source": [
        "# Beginning with n-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxB7hUOf5GIq"
      },
      "source": [
        "text = \"Hi everyone we can start the assignment by printing basic things\\\n",
        "so that it becomes easy to understand what we actually want to achieve from this\\\n",
        "assignment. Hope you enjoy the practical session of today and if you have any\\\n",
        "doubts you can always reach out to me\"\n",
        "token = nltk.word_tokenize(text)\n",
        "bigrams = ngrams(token,2)\n",
        "trigrams = ngrams(token,3)\n",
        "fourgrams = ngrams(token,4)\n",
        "fivegrams = ngrams(token,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3SmlM5n5N9W"
      },
      "source": [
        "### Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqRwgrpD5LZU",
        "outputId": "a19bceac-4934-4ece-e838-2c91f0897194"
      },
      "source": [
        "print(Counter(bigrams))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({('Hi', 'everyone'): 1, ('everyone', 'we'): 1, ('we', 'can'): 1, ('can', 'start'): 1, ('start', 'the'): 1, ('the', 'assignment'): 1, ('assignment', 'by'): 1, ('by', 'printing'): 1, ('printing', 'basic'): 1, ('basic', 'thingsso'): 1, ('thingsso', 'that'): 1, ('that', 'it'): 1, ('it', 'becomes'): 1, ('becomes', 'easy'): 1, ('easy', 'to'): 1, ('to', 'understand'): 1, ('understand', 'what'): 1, ('what', 'we'): 1, ('we', 'actually'): 1, ('actually', 'want'): 1, ('want', 'to'): 1, ('to', 'achieve'): 1, ('achieve', 'from'): 1, ('from', 'thisassignment'): 1, ('thisassignment', '.'): 1, ('.', 'Hope'): 1, ('Hope', 'you'): 1, ('you', 'enjoy'): 1, ('enjoy', 'the'): 1, ('the', 'practical'): 1, ('practical', 'session'): 1, ('session', 'of'): 1, ('of', 'today'): 1, ('today', 'and'): 1, ('and', 'if'): 1, ('if', 'you'): 1, ('you', 'have'): 1, ('have', 'anydoubts'): 1, ('anydoubts', 'you'): 1, ('you', 'can'): 1, ('can', 'always'): 1, ('always', 'reach'): 1, ('reach', 'out'): 1, ('out', 'to'): 1, ('to', 'me'): 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z5kK3dpjv2u"
      },
      "source": [
        "### Trigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQKXyJkg5Q4x",
        "outputId": "9b58dbdc-4b1b-4e47-9297-19a8b001e948"
      },
      "source": [
        "print(Counter(trigrams))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({('Hi', 'everyone', 'we'): 1, ('everyone', 'we', 'can'): 1, ('we', 'can', 'start'): 1, ('can', 'start', 'the'): 1, ('start', 'the', 'assignment'): 1, ('the', 'assignment', 'by'): 1, ('assignment', 'by', 'printing'): 1, ('by', 'printing', 'basic'): 1, ('printing', 'basic', 'thingsso'): 1, ('basic', 'thingsso', 'that'): 1, ('thingsso', 'that', 'it'): 1, ('that', 'it', 'becomes'): 1, ('it', 'becomes', 'easy'): 1, ('becomes', 'easy', 'to'): 1, ('easy', 'to', 'understand'): 1, ('to', 'understand', 'what'): 1, ('understand', 'what', 'we'): 1, ('what', 'we', 'actually'): 1, ('we', 'actually', 'want'): 1, ('actually', 'want', 'to'): 1, ('want', 'to', 'achieve'): 1, ('to', 'achieve', 'from'): 1, ('achieve', 'from', 'thisassignment'): 1, ('from', 'thisassignment', '.'): 1, ('thisassignment', '.', 'Hope'): 1, ('.', 'Hope', 'you'): 1, ('Hope', 'you', 'enjoy'): 1, ('you', 'enjoy', 'the'): 1, ('enjoy', 'the', 'practical'): 1, ('the', 'practical', 'session'): 1, ('practical', 'session', 'of'): 1, ('session', 'of', 'today'): 1, ('of', 'today', 'and'): 1, ('today', 'and', 'if'): 1, ('and', 'if', 'you'): 1, ('if', 'you', 'have'): 1, ('you', 'have', 'anydoubts'): 1, ('have', 'anydoubts', 'you'): 1, ('anydoubts', 'you', 'can'): 1, ('you', 'can', 'always'): 1, ('can', 'always', 'reach'): 1, ('always', 'reach', 'out'): 1, ('reach', 'out', 'to'): 1, ('out', 'to', 'me'): 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-9_9fV7j2Us"
      },
      "source": [
        "### Fourgrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoOMspJX5b-W",
        "outputId": "cfc942e6-8164-48ae-8f14-71f67e27202d"
      },
      "source": [
        "print(Counter(fourgrams))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({('Hi', 'everyone', 'we', 'can'): 1, ('everyone', 'we', 'can', 'start'): 1, ('we', 'can', 'start', 'the'): 1, ('can', 'start', 'the', 'assignment'): 1, ('start', 'the', 'assignment', 'by'): 1, ('the', 'assignment', 'by', 'printing'): 1, ('assignment', 'by', 'printing', 'basic'): 1, ('by', 'printing', 'basic', 'thingsso'): 1, ('printing', 'basic', 'thingsso', 'that'): 1, ('basic', 'thingsso', 'that', 'it'): 1, ('thingsso', 'that', 'it', 'becomes'): 1, ('that', 'it', 'becomes', 'easy'): 1, ('it', 'becomes', 'easy', 'to'): 1, ('becomes', 'easy', 'to', 'understand'): 1, ('easy', 'to', 'understand', 'what'): 1, ('to', 'understand', 'what', 'we'): 1, ('understand', 'what', 'we', 'actually'): 1, ('what', 'we', 'actually', 'want'): 1, ('we', 'actually', 'want', 'to'): 1, ('actually', 'want', 'to', 'achieve'): 1, ('want', 'to', 'achieve', 'from'): 1, ('to', 'achieve', 'from', 'thisassignment'): 1, ('achieve', 'from', 'thisassignment', '.'): 1, ('from', 'thisassignment', '.', 'Hope'): 1, ('thisassignment', '.', 'Hope', 'you'): 1, ('.', 'Hope', 'you', 'enjoy'): 1, ('Hope', 'you', 'enjoy', 'the'): 1, ('you', 'enjoy', 'the', 'practical'): 1, ('enjoy', 'the', 'practical', 'session'): 1, ('the', 'practical', 'session', 'of'): 1, ('practical', 'session', 'of', 'today'): 1, ('session', 'of', 'today', 'and'): 1, ('of', 'today', 'and', 'if'): 1, ('today', 'and', 'if', 'you'): 1, ('and', 'if', 'you', 'have'): 1, ('if', 'you', 'have', 'anydoubts'): 1, ('you', 'have', 'anydoubts', 'you'): 1, ('have', 'anydoubts', 'you', 'can'): 1, ('anydoubts', 'you', 'can', 'always'): 1, ('you', 'can', 'always', 'reach'): 1, ('can', 'always', 'reach', 'out'): 1, ('always', 'reach', 'out', 'to'): 1, ('reach', 'out', 'to', 'me'): 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8WQ9kKCj5vT"
      },
      "source": [
        "### Five Grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0BOaFhO5g3x",
        "outputId": "fc7824e3-cf0c-4e4f-bd4f-a6a7b6e30e81"
      },
      "source": [
        "print(Counter(fivegrams))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({('Hi', 'everyone', 'we', 'can', 'start'): 1, ('everyone', 'we', 'can', 'start', 'the'): 1, ('we', 'can', 'start', 'the', 'assignment'): 1, ('can', 'start', 'the', 'assignment', 'by'): 1, ('start', 'the', 'assignment', 'by', 'printing'): 1, ('the', 'assignment', 'by', 'printing', 'basic'): 1, ('assignment', 'by', 'printing', 'basic', 'thingsso'): 1, ('by', 'printing', 'basic', 'thingsso', 'that'): 1, ('printing', 'basic', 'thingsso', 'that', 'it'): 1, ('basic', 'thingsso', 'that', 'it', 'becomes'): 1, ('thingsso', 'that', 'it', 'becomes', 'easy'): 1, ('that', 'it', 'becomes', 'easy', 'to'): 1, ('it', 'becomes', 'easy', 'to', 'understand'): 1, ('becomes', 'easy', 'to', 'understand', 'what'): 1, ('easy', 'to', 'understand', 'what', 'we'): 1, ('to', 'understand', 'what', 'we', 'actually'): 1, ('understand', 'what', 'we', 'actually', 'want'): 1, ('what', 'we', 'actually', 'want', 'to'): 1, ('we', 'actually', 'want', 'to', 'achieve'): 1, ('actually', 'want', 'to', 'achieve', 'from'): 1, ('want', 'to', 'achieve', 'from', 'thisassignment'): 1, ('to', 'achieve', 'from', 'thisassignment', '.'): 1, ('achieve', 'from', 'thisassignment', '.', 'Hope'): 1, ('from', 'thisassignment', '.', 'Hope', 'you'): 1, ('thisassignment', '.', 'Hope', 'you', 'enjoy'): 1, ('.', 'Hope', 'you', 'enjoy', 'the'): 1, ('Hope', 'you', 'enjoy', 'the', 'practical'): 1, ('you', 'enjoy', 'the', 'practical', 'session'): 1, ('enjoy', 'the', 'practical', 'session', 'of'): 1, ('the', 'practical', 'session', 'of', 'today'): 1, ('practical', 'session', 'of', 'today', 'and'): 1, ('session', 'of', 'today', 'and', 'if'): 1, ('of', 'today', 'and', 'if', 'you'): 1, ('today', 'and', 'if', 'you', 'have'): 1, ('and', 'if', 'you', 'have', 'anydoubts'): 1, ('if', 'you', 'have', 'anydoubts', 'you'): 1, ('you', 'have', 'anydoubts', 'you', 'can'): 1, ('have', 'anydoubts', 'you', 'can', 'always'): 1, ('anydoubts', 'you', 'can', 'always', 'reach'): 1, ('you', 'can', 'always', 'reach', 'out'): 1, ('can', 'always', 'reach', 'out', 'to'): 1, ('always', 'reach', 'out', 'to', 'me'): 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is7dBeP5kA6a"
      },
      "source": [
        "# Working on Real Movie Review Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiAVzEb-6tFx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c8e0a652-70ab-4cf7-c46b-5b13d482831a"
      },
      "source": [
        "import pandas as pd\n",
        "train_data_sent = pd.read_csv('movie_review.csv')\n",
        "train_data_sent.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold_id</th>\n",
              "      <th>cv_tag</th>\n",
              "      <th>html_id</th>\n",
              "      <th>sent_id</th>\n",
              "      <th>text</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>0</td>\n",
              "      <td>films adapted from comic books have had plenty...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>1</td>\n",
              "      <td>for starters , it was created by alan moore ( ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>2</td>\n",
              "      <td>to say moore and campbell thoroughly researche...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>3</td>\n",
              "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>4</td>\n",
              "      <td>in other words , don't dismiss this film becau...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fold_id cv_tag  ...                                               text  tag\n",
              "0        0  cv000  ...  films adapted from comic books have had plenty...  pos\n",
              "1        0  cv000  ...  for starters , it was created by alan moore ( ...  pos\n",
              "2        0  cv000  ...  to say moore and campbell thoroughly researche...  pos\n",
              "3        0  cv000  ...  the book ( or \" graphic novel , \" if you will ...  pos\n",
              "4        0  cv000  ...  in other words , don't dismiss this film becau...  pos\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie3rK5rp613N"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import glob\n",
        "import random\n",
        "import seaborn as sns\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdHbjviLkIYI"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23yxusTY6-Qx"
      },
      "source": [
        "train_data_sent['sentence_clean'] = train_data_sent['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
        "train_data_sent['sentence_clean'] = train_data_sent['sentence_clean'].str.lower()\n",
        "#train_data_senti=train_data_sent\n",
        "train_data_sent=train_data_sent.head(1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "SFN1nDsHZA5Q",
        "outputId": "7019779d-552d-439f-9c63-9f7491b59ff6"
      },
      "source": [
        "train_data_sent.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold_id</th>\n",
              "      <th>cv_tag</th>\n",
              "      <th>html_id</th>\n",
              "      <th>sent_id</th>\n",
              "      <th>text</th>\n",
              "      <th>tag</th>\n",
              "      <th>sentence_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>0</td>\n",
              "      <td>films adapted from comic books have had plenty...</td>\n",
              "      <td>pos</td>\n",
              "      <td>films adapted from comic books have had plenty...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>1</td>\n",
              "      <td>for starters , it was created by alan moore ( ...</td>\n",
              "      <td>pos</td>\n",
              "      <td>for starters  it was created by alan moore  an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>2</td>\n",
              "      <td>to say moore and campbell thoroughly researche...</td>\n",
              "      <td>pos</td>\n",
              "      <td>to say moore and campbell thoroughly researche...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>3</td>\n",
              "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
              "      <td>pos</td>\n",
              "      <td>the book  or  graphic novel   if you will  is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>4</td>\n",
              "      <td>in other words , don't dismiss this film becau...</td>\n",
              "      <td>pos</td>\n",
              "      <td>in other words  dont dismiss this film because...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fold_id cv_tag  ...  tag                                     sentence_clean\n",
              "0        0  cv000  ...  pos  films adapted from comic books have had plenty...\n",
              "1        0  cv000  ...  pos  for starters  it was created by alan moore  an...\n",
              "2        0  cv000  ...  pos  to say moore and campbell thoroughly researche...\n",
              "3        0  cv000  ...  pos  the book  or  graphic novel   if you will  is ...\n",
              "4        0  cv000  ...  pos  in other words  dont dismiss this film because...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QqqG9BTaIKP"
      },
      "source": [
        "# Bigram Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMRJeul2ZLjn"
      },
      "source": [
        "from collections import defaultdict\n",
        "from nltk import bigrams, trigrams\n",
        "from collections import Counter\n",
        "\n",
        "model_2 = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "\n",
        "for sentence in train_data_sent['sentence_clean']:\n",
        "  #Split the sentence into bigrams inorder to count the frequencies of the bigrams\n",
        "  for w1, w2 in bigrams(sentence.split(), pad_right=True, pad_left=True):\n",
        "    model_2[(w1)][w2] += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTIzjKDyfIUr",
        "outputId": "49703af7-8015-40c4-ea67-f0cdf89d6d61"
      },
      "source": [
        "model_2['apart']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>.<locals>.<lambda>>,\n",
              "            {'as': 1, 'in': 1, 'tommys': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9ULtmgmabIJ",
        "outputId": "1bbecfb1-1229-4a1e-e725-08ff25d16922"
      },
      "source": [
        "print(\"The Number of times *america after* bigram has existed is \",model_2['america']['after'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Number of times *america after* bigram has existed is  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c79IRYnbakG8"
      },
      "source": [
        "for w1 in model_2:\n",
        "    total_count = float(sum(model_2[w1].values()))\n",
        "    for w2 in model_2[w1]:\n",
        "        model_2[w1][w2] /= total_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okS_t_q2pRFA",
        "outputId": "cf314a32-814b-4228-ee4e-3bac42dcc1df"
      },
      "source": [
        "model_2[('apart')]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>.<locals>.<lambda>>,\n",
              "            {'as': 0.3333333333333333,\n",
              "             'in': 0.3333333333333333,\n",
              "             'tommys': 0.3333333333333333})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjtIhpi2pmRj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}